{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GANde_v1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_jQ1tEQCxwRx"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6fC5ZbkDLP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J5oue0oqCkZZ",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g5RstiiB8V-z",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0-beta1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WZKbyU2-AiY-",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wx-zNbLqB4K8",
        "colab": {}
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YzTlj4YdCip_",
        "colab": {}
      },
      "source": [
        "# To generate GIFs\n",
        "!pip install imageio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YfIk2es3hJEd",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U9303rMGJn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTbwCAsAFFVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 7\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Remember that keras flow_from_directory() takes the inside folder as label\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "'/content/drive/My Drive/GANde/images/cropped_output',\n",
        "target_size=(32, 32),\n",
        "batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlQpBUBeK5Vl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-yKCCQOoJ7cn",
        "colab": {}
      },
      "source": [
        "# Batch and shuffle the data\n",
        "\n",
        "train_images, train_labels = train_generator.next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLoTFd7oNtUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# tf.get_default_graph()\n",
        "\n",
        "\n",
        "## optimizer\n",
        "#optimizer = Adam(0.0002, 0.5)\n",
        "optimizer = Adam(0.00007, 0.5)\n",
        "\n",
        "img_shape = (32,32, 3)\n",
        "\n",
        "def build_generator(img_shape, noise_shape = (100,)):\n",
        "    '''\n",
        "    noise_shape : the dimension of the input vector for the generator\n",
        "    img_shape   : the dimension of the output\n",
        "    '''\n",
        "    ## latent variable as input\n",
        "    input_noise = layers.Input(shape=noise_shape) \n",
        "    d = layers.Dense(1024, activation=\"relu\")(input_noise) \n",
        "    d = layers.Dense(1024, activation=\"relu\")(input_noise) \n",
        "    d = layers.Dense(128*8*8, activation=\"relu\")(d)\n",
        "    d = layers.Reshape((8,8,128))(d)\n",
        "    \n",
        "    d = layers.Conv2DTranspose(128, kernel_size=(2,2) ,  strides=(2,2) , use_bias=False)(d)\n",
        "    d = layers.Conv2D( 64  , ( 1 , 1 ) , activation='relu' , padding='same', name=\"block_4\")(d) ## 16,16\n",
        "\n",
        "\n",
        "    d = layers.Conv2DTranspose(32, kernel_size=(2,2) ,  strides=(2,2) , use_bias=False)(d)\n",
        "    d = layers.Conv2D( 64  , ( 1 , 1 ) , activation='relu' , padding='same', name=\"block_5\")(d) ## 32,32\n",
        "    \n",
        "    if img_shape[0] == 64:\n",
        "        d = layers.Conv2DTranspose(32, kernel_size=(2,2) ,  strides=(2,2) , use_bias=False)(d)\n",
        "        d = layers.Conv2D( 64  , ( 1 , 1 ) , activation='relu' , padding='same', name=\"block_6\")(d) ## 64,64\n",
        "    \n",
        "    img = layers.Conv2D( 3 , ( 1 , 1 ) , activation='sigmoid' , padding='same', name=\"final_block\")(d) ## 32, 32\n",
        "    model = models.Model(input_noise, img)\n",
        "    model.summary() \n",
        "    return(model)\n",
        "\n",
        "## Set the dimension of latent variables to be 100\n",
        "noise_shape = (100,)\n",
        "\n",
        "generator = build_generator(img_shape, noise_shape = noise_shape)\n",
        "\n",
        "generator.compile(loss='binary_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlonQr1kNvAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def get_noise(nsample=1, nlatent_dim=100):\n",
        "    noise = np.random.normal(0, 1, (nsample,nlatent_dim))\n",
        "    return(noise)\n",
        "\n",
        "def plot_generated_images(noise,path_save=None,titleadd=\"\"):\n",
        "    imgs = generator.predict(noise)\n",
        "    fig = plt.figure(figsize=(40,10))\n",
        "    for i, img in enumerate(imgs):\n",
        "        ax = fig.add_subplot(1,nsample,i+1)\n",
        "        ax.imshow(img)\n",
        "    fig.suptitle(\"Generated images \"+titleadd,fontsize=30)\n",
        "    \n",
        "    if path_save is not None:\n",
        "        plt.savefig(path_save,\n",
        "                    bbox_inches='tight',\n",
        "                    pad_inches=0)\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "nsample = 4\n",
        "noise = get_noise(nsample=nsample, nlatent_dim=noise_shape[0])\n",
        "plot_generated_images(noise)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFN-aYDkNzDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator(img_shape,noutput=1):\n",
        "    input_img = layers.Input(shape=img_shape)\n",
        "    \n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='block1_conv1')(input_img)\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "    \n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "    \n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(1, 1), name='block4_pool')(x)\n",
        "\n",
        "    \n",
        "    x         = layers.Flatten()(x)\n",
        "    x         = layers.Dense(1024,      activation=\"relu\")(x)\n",
        "    out       = layers.Dense(noutput,   activation='sigmoid')(x)\n",
        "    model     = models.Model(input_img, out)\n",
        "    \n",
        "    return model\n",
        "\n",
        "discriminator  = build_discriminator(img_shape)\n",
        "discriminator.compile(loss      = 'binary_crossentropy', \n",
        "                      optimizer = optimizer,\n",
        "                      metrics   = ['accuracy'])\n",
        "\n",
        "discriminator.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxMyHi5yN2qx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "z = layers.Input(shape=noise_shape)\n",
        "img = generator(z)\n",
        "\n",
        "# For the combined model we will only train the generator\n",
        "discriminator.trainable = False\n",
        "\n",
        "# The valid takes generated images as input and determines validity\n",
        "valid = discriminator(img)\n",
        "\n",
        "# The combined model  (stacked generator and discriminator) takes\n",
        "# noise as input => generates images => determines validity \n",
        "combined = models.Model(z, valid)\n",
        "combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "combined.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi_NjpxDN5hq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(models, X_train, noise_plot, dir_result=\"/result/\", epochs=10000, batch_size=128):\n",
        "        '''\n",
        "        models     : tuple containins three tensors, (combined, discriminator, generator)\n",
        "        X_train    : np.array containing images (Nsample, height, width, Nchannels)\n",
        "        noise_plot : np.array of size (Nrandom_sample_to_plot, hidden unit length)\n",
        "        dir_result : the location where the generated plots for noise_plot are saved \n",
        "        \n",
        "        '''\n",
        "        combined, discriminator, generator = models\n",
        "        nlatent_dim = noise_plot.shape[1]\n",
        "        half_batch  = int(batch_size / 2)\n",
        "        history = []\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            # ---------------------\n",
        "            #  Train Discriminator\n",
        "            # ---------------------\n",
        "\n",
        "            # Select a random half batch of images\n",
        "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
        "            imgs = X_train[idx]\n",
        "            noise = get_noise(half_batch, nlatent_dim)\n",
        "\n",
        "            # Generate a half batch of new images\n",
        "            gen_imgs = generator.predict(noise)\n",
        "\n",
        "            \n",
        "            # Train the discriminator q: better to mix them together?\n",
        "            d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
        "            d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "\n",
        "            # ---------------------\n",
        "            #  Train Generator\n",
        "            # ---------------------\n",
        "\n",
        "            noise = get_noise(batch_size, nlatent_dim)\n",
        "\n",
        "            # The generator wants the discriminator to label the generated samples\n",
        "            # as valid (ones)\n",
        "            valid_y = (np.array([1] * batch_size)).reshape(batch_size,1)\n",
        "            \n",
        "            # Train the generator\n",
        "            g_loss = combined.train_on_batch(noise, valid_y)\n",
        "\n",
        "            history.append({\"D\":d_loss[0],\"G\":g_loss})\n",
        "            \n",
        "            if epoch % 100 == 0:\n",
        "                # Plot the progress\n",
        "                print (\"Epoch {:05.0f} [D loss: {:4.3f}, acc.: {:05.1f}%] [G loss: {:4.3f}]\".format(\n",
        "                    epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "            if epoch % int(epochs/100) == 0:\n",
        "                plot_generated_images(noise_plot,\n",
        "                                      path_save=dir_result+\"/image_{:05.0f}.png\".format(epoch),\n",
        "                                      titleadd=\"Epoch {}\".format(epoch))\n",
        "            if epoch % 500 == 0:\n",
        "                plot_generated_images(noise_plot,\n",
        "                                      titleadd=\"Epoch {}\".format(epoch))\n",
        "                        \n",
        "        return(history)\n",
        "\n",
        "# dir_result=\"./result_GAN/\"\n",
        "\n",
        "# try:\n",
        "#     os.mkdir(dir_result)\n",
        "# except:\n",
        "#     pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5JTOU3geHUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir_base = '/content/drive/My Drive/GANde/images/GAN_output'\n",
        "\n",
        "dir_subfolder = \"/GAN_output_4\" # CHANGEABLE, create it beforehand\n",
        "\n",
        "dir_result = dir_base + dir_subfolder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6v0NwpkYiRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_time = time.time()\n",
        "\n",
        "_models = combined, discriminator, generator          \n",
        "\n",
        "history = train(_models, train_images, noise, dir_result=dir_result,epochs=1200, batch_size=7)\n",
        "end_time = time.time()\n",
        "print(\"-\"*10)\n",
        "print(\"Time took: {:4.2f} min\".format((end_time - start_time)/60))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxY5OtMrZZMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def makegif(dir_images):\n",
        "    import imageio\n",
        "    filenames = np.sort(os.listdir(dir_images))\n",
        "    filenames = [ fnm for fnm in filenames if \".png\" in fnm]\n",
        "\n",
        "    with imageio.get_writer(dir_images + '/image.gif', mode='I') as writer:\n",
        "        for filename in filenames:\n",
        "            image = imageio.imread(dir_images + filename)\n",
        "            writer.append_data(image)\n",
        "            os.remove(dir_images + filename)\n",
        "            \n",
        "makegif(dir_result + '/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tlwt2j6MeXZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}